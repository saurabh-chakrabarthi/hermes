name: CI/CD Pipeline

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

env:
  JAVA_VERSION: '17'

jobs:
  # JUnit Tests
  junit-tests:
    name: "üß™ JUnit Tests"
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Java
      uses: actions/setup-java@v4
      with:
        java-version: ${{ env.JAVA_VERSION }}
        distribution: 'temurin'
        
    - name: Cache Maven dependencies
      uses: actions/cache@v3
      with:
        path: ~/.m2
        key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
        
    - name: Run JUnit Tests
      if: |
        contains(github.event.head_commit.modified, 'client/') ||
        contains(github.event.head_commit.added, 'client/') ||
        github.event_name == 'pull_request'
      run: |
        echo "üß™ Running JUnit tests..."
        cd client
        mvn clean test
        
    - name: Upload Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results
        path: client/target/surefire-reports/

  # Test Node.js Server
  test-nodejs:
    name: "üü¢ Node.js Tests"
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: server/package-lock.json
        
    - name: Install dependencies
      working-directory: ./server
      run: npm ci
      
    - name: Run tests
      if: |
        contains(github.event.head_commit.modified, 'server/') ||
        contains(github.event.head_commit.added, 'server/') ||
        github.event_name == 'pull_request'
      working-directory: ./server
      run: npm test || echo "No tests defined yet"

  # Build and Push Docker Images
  build-images:
    name: "üê≥ Build Docker Images"
    runs-on: ubuntu-latest
    needs: [junit-tests, test-nodejs]
    if: |
      github.ref == 'refs/heads/main' && 
      github.event_name == 'push' &&
      (needs.junit-tests.result == 'success' || needs.junit-tests.result == 'skipped') &&
      (needs.test-nodejs.result == 'success' || needs.test-nodejs.result == 'skipped')
    permissions:
      contents: read
      packages: write
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Log in to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata for payment-server
      id: meta-server
      uses: docker/metadata-action@v5
      with:
        images: ghcr.io/${{ github.repository_owner }}/hermes-payment-server
        tags: |
          type=raw,value=latest
          type=sha,prefix={{branch}}-
    
    - name: Build and push payment-server
      uses: docker/build-push-action@v5
      with:
        context: ./server
        push: true
        tags: ${{ steps.meta-server.outputs.tags }}
        labels: ${{ steps.meta-server.outputs.labels }}
    
    - name: Extract metadata for payment-dashboard
      id: meta-dashboard
      uses: docker/metadata-action@v5
      with:
        images: ghcr.io/${{ github.repository_owner }}/hermes-payment-dashboard-micronaut
        tags: |
          type=raw,value=latest
          type=sha,prefix={{branch}}-
    
    - name: Build and push payment-dashboard (Micronaut)
      uses: docker/build-push-action@v5
      with:
        context: ./dashboard
        push: true
        tags: ${{ steps.meta-dashboard.outputs.tags }}
        labels: ${{ steps.meta-dashboard.outputs.labels }}

  # Deploy Infrastructure and Application
  deploy:
    name: "üöÄ Deploy to OCI"
    runs-on: ubuntu-latest
    needs: [build-images]
    if: |
      github.ref == 'refs/heads/main' && 
      github.event_name == 'push' &&
      always() &&
      (needs.build-images.result == 'success' || needs.build-images.result == 'skipped')
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.6.0
    
    - name: Setup OCI CLI
      run: |
        curl -L https://raw.githubusercontent.com/oracle/oci-cli/master/scripts/install/install.sh | bash -s -- --accept-all-defaults
        export PATH="$HOME/bin:$PATH"
        echo "PATH=$HOME/bin:$PATH" >> $GITHUB_ENV
        
        # Create OCI config
        mkdir -p ~/.oci
        cat > ~/.oci/config << EOF
        [DEFAULT]
        user=${{ secrets.OCI_USER_OCID }}
        fingerprint=${{ secrets.OCI_FINGERPRINT }}
        tenancy=${{ secrets.OCI_TENANCY_OCID }}
        region=${{ secrets.OCI_REGION }}
        key_file=$HOME/.oci/key.pem
        EOF
        
        # Create private key file (handle potential formatting issues)
        echo "${{ secrets.OCI_PRIVATE_KEY }}" > ~/.oci/key.pem
        chmod 600 ~/.oci/key.pem
        
        # Validate private key format
        echo "Private key validation:"
        head -1 ~/.oci/key.pem
        tail -1 ~/.oci/key.pem
        wc -l ~/.oci/key.pem
        
        # Verify setup
        echo "OCI CLI version:"
        oci --version
        echo "Config file:"
        cat ~/.oci/config
        echo "Key file permissions:"
        ls -la ~/.oci/key.pem
        
        # Test OCI authentication
        echo "Testing OCI authentication:"
        oci iam compartment get --compartment-id ${{ secrets.OCI_COMPARTMENT_ID }} || echo "Auth test failed"
    
    - name: Cleanup Old Resources
      run: |
        export PATH="$HOME/bin:$PATH"
        echo "Cleaning up duplicate VCNs..."
        
        # Get all VCNs named hermes-vcn and delete them
        VCN_IDS=$(oci network vcn list --compartment-id ${{ secrets.OCI_COMPARTMENT_ID }} --display-name "hermes-vcn" --query "data[].id" --raw-output 2>/dev/null || echo "")
        
        if [ ! -z "$VCN_IDS" ]; then
          echo "Found duplicate hermes-vcn VCNs to delete"
          for vcn_id in $VCN_IDS; do
            echo "Deleting VCN: $vcn_id"
            # Delete associated resources first, then VCN
            oci network vcn delete --vcn-id $vcn_id --force --wait-for-state TERMINATED 2>/dev/null || echo "Failed to delete VCN $vcn_id"
          done
        else
          echo "No duplicate VCNs found"
        fi
    
    - name: Validate Secrets
      run: |
        echo "Validating required secrets..."
        
        if [ -z "${{ secrets.MONGODB_PASSWORD }}" ]; then
          echo "‚ùå ERROR: MONGODB_PASSWORD secret is not set!"
          echo "Please add MONGODB_PASSWORD to GitHub Secrets"
          exit 1
        fi
        
        if [ -z "${{ secrets.OCI_USER_OCID }}" ]; then
          echo "‚ùå ERROR: OCI_USER_OCID secret is not set!"
          exit 1
        fi
        
        echo "‚úÖ All required secrets are set"
    
    - name: Check Instance Metadata
      id: check_instance
      run: |
        export PATH="$HOME/bin:$PATH"
        echo "Checking existing instance metadata..."
        
        INSTANCE_ID=$(oci compute instance list \
          --compartment-id ${{ secrets.OCI_COMPARTMENT_ID }} \
          --display-name "hermes-payment-portal" \
          --lifecycle-state RUNNING \
          --query "data[0].id" \
          --raw-output 2>/dev/null || echo "")
        
        if [ ! -z "$INSTANCE_ID" ] && [ "$INSTANCE_ID" != "null" ]; then
          echo "Found existing instance: $INSTANCE_ID"
          
          # Get current deployment_trigger from instance metadata
          CURRENT_TRIGGER=$(oci compute instance get \
            --instance-id $INSTANCE_ID \
            --query 'data."metadata"."deployment_trigger"' \
            --raw-output 2>/dev/null || echo "")
          
          echo "Current deployment_trigger: $CURRENT_TRIGGER"
          echo "New deployment_trigger: 4"
          
          if [ "$CURRENT_TRIGGER" != "4" ]; then
            echo "Deployment trigger changed - terminating instance..."
            oci compute instance terminate --instance-id $INSTANCE_ID --force --wait-for-state TERMINATED
            echo "‚úÖ Instance terminated"
            echo "recreate=true" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ Instance already up to date"
            echo "recreate=false" >> $GITHUB_OUTPUT
          fi
        else
          echo "No existing instance found - will create new one"
          echo "recreate=true" >> $GITHUB_OUTPUT
        fi
    
    - name: Deploy Infrastructure
      working-directory: ./infra/terraform
      env:
        TF_VAR_user_ocid: ${{ secrets.OCI_USER_OCID }}
        TF_VAR_fingerprint: ${{ secrets.OCI_FINGERPRINT }}
        TF_VAR_tenancy_ocid: ${{ secrets.OCI_TENANCY_OCID }}
        TF_VAR_region: ${{ secrets.OCI_REGION }}
        TF_VAR_private_key: ${{ secrets.OCI_PRIVATE_KEY }}
        TF_VAR_compartment_id: ${{ secrets.OCI_COMPARTMENT_ID }}
        TF_VAR_ssh_public_key: ${{ secrets.SSH_PUBLIC_KEY }}
        TF_VAR_mongodb_password: ${{ secrets.MONGODB_PASSWORD }}
        TF_VAR_github_owner: ${{ github.repository_owner }}
      run: |
        export PATH="$HOME/bin:$PATH"
        
        # Debug: Check if variables are set
        echo "Checking Terraform variables:"
        echo "User OCID: ${TF_VAR_user_ocid:0:20}..."
        echo "Fingerprint: $TF_VAR_fingerprint"
        echo "Tenancy OCID: ${TF_VAR_tenancy_ocid:0:20}..."
        echo "Region: $TF_VAR_region"
        echo "Private key first line: $(echo "$TF_VAR_private_key" | head -1)"
        echo "Private key last line: $(echo "$TF_VAR_private_key" | tail -1)"
        echo "Private key line count: $(echo "$TF_VAR_private_key" | wc -l)"
        
        terraform init
        terraform plan
        terraform apply -auto-approve
        
        # Get instance IP with error handling
        echo "Extracting instance IP..."
        terraform output -json
        
        INSTANCE_IP=$(terraform output -raw instance_public_ip 2>&1)
        if [ -z "$INSTANCE_IP" ] || [ "$INSTANCE_IP" == "null" ]; then
          echo "‚ùå ERROR: Failed to get instance IP from Terraform output"
          echo "Terraform outputs:"
          terraform output
          exit 1
        fi
        
        echo "INSTANCE_IP=$INSTANCE_IP" >> $GITHUB_ENV
        echo "‚úÖ Terraform completed. Instance IP: $INSTANCE_IP"
        
        echo "üîí Security Validation:"
        terraform output -json security_validation | jq -r 'to_entries[] | "\(.key): \(.value)"'
        
        # Check if all ports are open
        ALL_PORTS_STATUS=$(terraform output -json security_validation | jq -r '.all_ports_open')
        if [[ "$ALL_PORTS_STATUS" != *"‚úÖ"* ]]; then
          echo "‚ùå ERROR: Required ports are blocked!"
          terraform output -json security_validation | jq .
          exit 1
        fi
        echo "‚úÖ All required ports are open"
    
    - name: Wait for Docker Services
      run: |
        echo "Waiting for Docker installation and container startup..."
        echo "Instance IP: $INSTANCE_IP"
        echo "This may take 5-7 minutes (Docker install + MySQL init + image pull)"
        
        # Wait for cloud-init and Docker setup
        echo "Waiting 3 minutes for Docker installation..."
        sleep 180
        
        # Wait for health endpoint with better feedback
        echo "Checking service health (up to 5 minutes)..."
        for i in {1..60}; do
          echo "Attempt $i/60: Checking http://$INSTANCE_IP:30092/health"
          if curl -f -m 5 http://$INSTANCE_IP:30092/health 2>/dev/null; then
            echo "‚úÖ Services ready!"
            exit 0
          fi
          sleep 5
        done
        
        echo "‚ö†Ô∏è Service did not start in time. Check logs manually:"
        echo "ssh -i ~/.ssh/hermes-pvt-key.key ubuntu@$INSTANCE_IP"
        echo "kubectl get pods -n hermes"
        echo "kubectl logs -n hermes -l app=payment-server"
        echo "kubectl logs -n hermes -l app=mysql"
        exit 1
    
    - name: Health Check
      run: |
        echo "=== Checking Node.js Server Health ==="
        
        # Get health response (allow non-200 status codes)
        HEALTH_RESPONSE=$(curl -s http://$INSTANCE_IP:30092/health)
        HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://$INSTANCE_IP:30092/health)
        
        echo "HTTP Status: $HTTP_CODE"
        echo "Response:"
        echo $HEALTH_RESPONSE | jq .
        
        # Parse response
        OVERALL_STATUS=$(echo $HEALTH_RESPONSE | jq -r '.status')
        MYSQL_STATUS=$(echo $HEALTH_RESPONSE | jq -r '.services.mysql.status')
        MYSQL_ERROR=$(echo $HEALTH_RESPONSE | jq -r '.services.mysql.error')
        REDIS_STATUS=$(echo $HEALTH_RESPONSE | jq -r '.services.redis.status')
        REDIS_ERROR=$(echo $HEALTH_RESPONSE | jq -r '.services.redis.error')
        
        echo ""
        echo "=== Service Status ==="
        echo "Overall: $OVERALL_STATUS"
        echo "MySQL: $MYSQL_STATUS"
        if [ "$MYSQL_ERROR" != "null" ]; then
          echo "  Error: $MYSQL_ERROR"
        fi
        echo "Redis: $REDIS_STATUS"
        if [ "$REDIS_ERROR" != "null" ]; then
          echo "  Error: $REDIS_ERROR"
        fi
        
        # Fail if MySQL is not connected
        if [ "$MYSQL_STATUS" != "connected" ]; then
          echo ""
          echo "‚ùå DEPLOYMENT FAILED: MySQL not connected!"
          echo "Error: $MYSQL_ERROR"
          echo ""
          echo "Troubleshooting:"
          echo "1. Check if DB_PASSWORD secret is set correctly"
          echo "2. SSH to VM: ssh -i ~/.ssh/hermes-pvt-key.key ubuntu@$INSTANCE_IP"
          echo "3. Check MySQL logs: kubectl logs -n hermes -l app=mysql"
          echo "4. Check server logs: kubectl logs -n hermes -l app=payment-server"
          exit 1
        fi
        
        # Fail if Redis is not connected
        if [ "$REDIS_STATUS" != "connected" ]; then
          echo ""
          echo "‚ùå DEPLOYMENT FAILED: Redis not connected!"
          echo "Error: $REDIS_ERROR"
          echo ""
          echo "Troubleshooting:"
          echo "1. SSH to VM: ssh -i ~/.ssh/hermes-pvt-key.key ubuntu@$INSTANCE_IP"
          echo "2. Check Redis logs: kubectl logs -n hermes -l app=redis"
          echo "3. Check server logs: kubectl logs -n hermes -l app=payment-server"
          exit 1
        fi
        
        echo ""
        echo "‚úÖ Node.js server healthy"
        
        echo ""
        echo "=== Checking Spring Boot Client ==="
        DASHBOARD_HEALTH=$(curl -s http://$INSTANCE_IP:30080/actuator/health)
        echo $DASHBOARD_HEALTH | jq .
        
        DASHBOARD_STATUS=$(echo $DASHBOARD_HEALTH | jq -r '.status')
        if [ "$DASHBOARD_STATUS" != "UP" ]; then
          echo "‚ùå Spring Boot client not healthy: $DASHBOARD_STATUS"
          exit 1
        fi
        
        echo "‚úÖ Spring Boot client healthy"
        
        echo ""
        echo "====================================="
        echo "‚úÖ DEPLOYMENT SUCCESSFUL!"
        echo "====================================="
        echo "üîµ Node.js Server: http://$INSTANCE_IP:30092"
        echo "üü¢ Spring Boot Dashboard: http://$INSTANCE_IP:30080"
        echo "üü¢ MySQL: $MYSQL_STATUS"
        echo "üî¥ Redis: $REDIS_STATUS"
        echo "====================================="